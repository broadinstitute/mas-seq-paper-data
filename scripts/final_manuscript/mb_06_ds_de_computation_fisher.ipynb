{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differential Expression (DE) and Differential Splicing (DS) analysis\n",
    "\n",
    "**Inputs and Outputs**\n",
    "- Inputs:\n",
    "  - Harmonized and annotated short-read and long-read AnnData (raw, SCT)\n",
    "- Outputs:\n",
    "  - Figures\n",
    "  - Tables of global and per-cluster DE and DS pvalues for all genes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "import logging\n",
    "import pickle\n",
    "from operator import itemgetter\n",
    "import json, pprint\n",
    "import tables \n",
    "\n",
    "import scanpy as sc\n",
    "import anndata\n",
    "\n",
    "from collections import defaultdict\n",
    "from itertools import groupby\n",
    "from operator import itemgetter\n",
    "from typing import List, Dict, Union, Any\n",
    "\n",
    "from time import time\n",
    "\n",
    "SMALL_SIZE = 12\n",
    "MEDIUM_SIZE = 14\n",
    "BIGGER_SIZE = 16\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "log_info = logger.warning\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "sc.settings.set_figure_params(dpi=80, facecolor='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_root = '/home/jupyter/mb-ml-data-disk/MAS-seq-analysis'\n",
    "\n",
    "# inputs\n",
    "input_prefix = 'M132TS_immune.revised_v2.harmonized'\n",
    "output_path = 'output/t-cell-vdj-cite-seq'\n",
    "\n",
    "# outputs\n",
    "final_long_adata_raw_h5_path = os.path.join(repo_root, output_path, f'{input_prefix}.long.stringtie.final.raw.h5ad')\n",
    "final_short_adata_raw_h5_path = os.path.join(repo_root, output_path, f'{input_prefix}.short.stringtie.final.raw.h5ad')\n",
    "final_long_adata_sct_h5_path = os.path.join(repo_root, output_path, f'{input_prefix}.long.stringtie.final.sct.h5ad')\n",
    "final_short_adata_sct_h5_path = os.path.join(repo_root, output_path, f'{input_prefix}.short.stringtie.final.sct.h5ad')\n",
    "\n",
    "# differentially spliced\n",
    "group_resolved_ds_df_csv_path = os.path.join(repo_root, output_path, f'{input_prefix}.group_resolved.ds.csv')\n",
    "group_resolved_ds_de_df_csv_path = os.path.join(repo_root, output_path, f'{input_prefix}.group_resolved.ds.de.csv')\n",
    "global_ds_df_csv_path = os.path.join(repo_root, output_path, f'{input_prefix}.global.ds.csv')\n",
    "global_ds_de_df_csv_path = os.path.join(repo_root, output_path, f'{input_prefix}.global.ds.de.csv')\n",
    "\n",
    "# constants\n",
    "GENE_IDS_KEY = 'gene_ids'\n",
    "GENE_NAMES_KEY = 'gene_names'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_cells_per_transcript = 1\n",
    "min_cells_per_gene = 10\n",
    "\n",
    "group_cells_by_obs_key = 'mehrtash_leiden'\n",
    "\n",
    "test_mode = False\n",
    "\n",
    "if test_mode:\n",
    "    n_mc_samples = 100\n",
    "    save_results = False\n",
    "    \n",
    "else:\n",
    "    n_mc_samples = 1_000_000\n",
    "    save_results = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_long = sc.read(os.path.join(repo_root, final_long_adata_raw_h5_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_umis = adata_long.X.sum()\n",
    "log_info(f'Total UMIs: {total_umis}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove genes that are lowly expressed\n",
    "from collections import defaultdict\n",
    "gene_id_to_tx_indices_map = defaultdict(list)\n",
    "for i, gid in enumerate(adata_long.var[GENE_IDS_KEY].values):\n",
    "    gene_id_to_tx_indices_map[gid].append(i)\n",
    "\n",
    "included_gene_ids = []\n",
    "tx_counts_i = np.asarray(adata_long.X.sum(0)).flatten()\n",
    "for gid, tx_indices in gene_id_to_tx_indices_map.items():\n",
    "    if np.sum(tx_counts_i[tx_indices]) >= min_cells_per_gene:\n",
    "        included_gene_ids.append(gid)\n",
    "\n",
    "adata_long = adata_long[:, adata_long.var[GENE_IDS_KEY].values.isin(included_gene_ids)]\n",
    "\n",
    "# remove transcript that are very lowly expressed\n",
    "sc.pp.filter_genes(adata_long, min_cells=min_cells_per_transcript)\n",
    "tpm_threshold = 1_000_000 * min_cells_per_transcript / total_umis\n",
    "\n",
    "log_info(f'Removing isoforms with TPM < {tpm_threshold:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_long"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isoform DE analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping from gene id to spanning tx icatces\n",
    "from collections import defaultdict\n",
    "gene_id_to_tx_indices_map = defaultdict(list)\n",
    "for i, gid in enumerate(adata_long.var[GENE_IDS_KEY].values):\n",
    "    gene_id_to_tx_indices_map[gid].append(i)\n",
    "\n",
    "# useful auxiliary data structures    \n",
    "gene_ids = sorted(list(gene_id_to_tx_indices_map.keys()))\n",
    "n_genes = len(gene_ids)\n",
    "gene_id_to_gene_name_map = {\n",
    "    gene_id: gene_name for gene_id, gene_name in zip(adata_long.var[GENE_IDS_KEY], adata_long.var[GENE_NAMES_KEY])}\n",
    "gene_name_to_gene_id_map = {\n",
    "    gene_name: gene_id for gene_id, gene_name in zip(adata_long.var[GENE_IDS_KEY], adata_long.var[GENE_NAMES_KEY])}\n",
    "gene_names = list(map(gene_id_to_gene_name_map.get, gene_ids))\n",
    "\n",
    "# mapping from gene id to spanning tx indices\n",
    "group_ids = adata_long.obs[group_cells_by_obs_key].values.categories.values\n",
    "group_id_to_obs_indices_map = defaultdict(list)\n",
    "for group_id in group_ids:\n",
    "    group_id_to_obs_indices_map[group_id] = [\n",
    "        idx for idx in range(len(adata_long))\n",
    "        if adata_long.obs[group_cells_by_obs_key].values[idx] == group_id]\n",
    "    \n",
    "# reduce tx expression by group (e.g. leiden clusters)\n",
    "n_transcripts = adata_long.shape[1]\n",
    "n_groups = len(group_id_to_obs_indices_map)\n",
    "group_expr_gi = np.zeros((n_groups, n_transcripts), dtype=np.int)\n",
    "for i_group, group_id in enumerate(group_ids):\n",
    "    group_expr_gi[i_group, :] = np.asarray(adata_long.X[group_id_to_obs_indices_map[group_id], :].sum(0)).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global differential splicing analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Tuple, Any, List\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from tqdm import tqdm\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from rpy2 import rinterface as ri\n",
    "from rpy2 import robjects\n",
    "from rpy2.rinterface_lib.embedded import RRuntimeError\n",
    "\n",
    "ri.initr()\n",
    "\n",
    "def get_global_ds_pval_fisher(\n",
    "        gene_id: str,\n",
    "        gene_id_to_tx_indices_map: Dict[str, List[int]],\n",
    "        group_expr_gi: np.ndarray,\n",
    "        n_mc_samples: int = 10_000) -> Dict[str, Any]:\n",
    "\n",
    "    tx_indices = gene_id_to_tx_indices_map[gene_id]\n",
    "    n_groups = group_expr_gi.shape[0]\n",
    "    x_gi = group_expr_gi[:, tx_indices]\n",
    "    x_g = np.sum(x_gi, -1)\n",
    "    x_i = np.sum(x_gi, -2)\n",
    "    \n",
    "    if len(tx_indices) < 2 or np.sum(x_g > 0) < 2 or np.sum(x_i > 0) < 2:\n",
    "        return {\n",
    "            'pval': 1.,\n",
    "            'x_g': x_g\n",
    "        }\n",
    "    \n",
    "\n",
    "    def rimport(packname):\n",
    "        as_environment = ri.baseenv['as.environment']\n",
    "        require = ri.baseenv['require']\n",
    "        require(ri.StrSexpVector([packname]),\n",
    "                quiet = ri.BoolSexpVector((True, )))\n",
    "        packname = ri.StrSexpVector(['package:' + str(packname)])\n",
    "        pack_env = as_environment(packname)\n",
    "        return pack_env\n",
    "    \n",
    "    rstats = rimport('stats')\n",
    "    \n",
    "    args = (('x', robjects.r.matrix(robjects.IntVector(x_gi.flat), nrow=n_groups, byrow=True)),\n",
    "            ('simulate.p.value', True),\n",
    "            ('B', n_mc_samples))\n",
    "    \n",
    "    try:\n",
    "        out = rstats['fisher.test'].rcall(args, ri.globalenv)\n",
    "        pval = float(np.array(np.array(out)[0])[0])\n",
    "        \n",
    "    except RRuntimeError:\n",
    "        print(x_gi)\n",
    "        raise RuntimeError\n",
    "\n",
    "    return {\n",
    "        'pval': pval,\n",
    "        'x_g': x_g\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_id_to_p_values_map = dict()\n",
    "gene_id_to_x_g_map = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "remaining_gene_ids = list(set(gene_ids).difference(gene_id_to_p_values_map.keys()))\n",
    "num_processes = cpu_count()\n",
    "\n",
    "def process_gene_id(gene_id: str) -> Dict[str, Any]:\n",
    "\n",
    "    out = get_global_ds_pval_fisher(\n",
    "        gene_id=gene_id,\n",
    "        gene_id_to_tx_indices_map=gene_id_to_tx_indices_map,\n",
    "        group_expr_gi=group_expr_gi,\n",
    "        n_mc_samples=n_mc_samples)\n",
    "    \n",
    "    return {\n",
    "        'gene_id': gene_id,\n",
    "        'pval': out['pval'],\n",
    "        'x_g': out['x_g']\n",
    "    }\n",
    "\n",
    "with Pool(processes=num_processes) as pool:\n",
    "    for result in tqdm(pool.imap(func=process_gene_id, iterable=remaining_gene_ids), total=len(remaining_gene_ids)):\n",
    "        gene_id_to_p_values_map[result['gene_id']] = result['pval']\n",
    "        gene_id_to_x_g_map[result['gene_id']] = result['x_g']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate dataframe\n",
    "group_total_counts_dict = dict()\n",
    "for i_group, group_iad in enumerate(group_ids):\n",
    "    group_total_counts_dict[f'expr_{i_group}'] = list(map(lambda gene_id: gene_id_to_x_g_map[gene_id][i_group], gene_ids))\n",
    "group_total_counts_dict['total_expr'] = list(map(lambda gene_id: np.sum(gene_id_to_x_g_map[gene_id]), gene_ids))\n",
    "\n",
    "ds_pval_global = list(map(gene_id_to_p_values_map.get, gene_ids))\n",
    "_, ds_pval_global_adj, _, _ = multipletests(ds_pval_global, alpha=0.05, method='fdr_bh')\n",
    "\n",
    "global_ds_df = pd.DataFrame({\n",
    "    **dict(\n",
    "        gene_ids=gene_ids),\n",
    "    **group_total_counts_dict,\n",
    "    **dict(\n",
    "        ds_pval_global=ds_pval_global,\n",
    "        ds_pval_global_adj=ds_pval_global_adj)},\n",
    "    index=list(map(gene_id_to_gene_name_map.get, gene_ids)))\n",
    "\n",
    "if save_results:\n",
    "    global_ds_df.to_csv(global_ds_df_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_ds_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group-resolved differential splicing analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Tuple, Any\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from tqdm import tqdm\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from rpy2 import rinterface as ri\n",
    "from rpy2 import robjects\n",
    "from rpy2.rinterface_lib.embedded import RRuntimeError\n",
    "\n",
    "ri.initr()\n",
    "\n",
    "def get_group_resolved_ds_pval_fisher(\n",
    "        gene_id: str,\n",
    "        gene_id_to_tx_indices_map: Dict[str, List[int]],\n",
    "        group_expr_gi: np.ndarray,\n",
    "        n_mc_samples: int = 10_000) -> Dict[str, Any]:\n",
    "\n",
    "    tx_indices = gene_id_to_tx_indices_map[gene_id]\n",
    "    n_groups = group_expr_gi.shape[0]\n",
    "    x_gi = group_expr_gi[:, tx_indices]\n",
    "    x_g = np.sum(x_gi, -1)\n",
    "    \n",
    "    if len(tx_indices) < 2:\n",
    "        return {\n",
    "            'pval_g': np.ones((n_groups,)),\n",
    "            'x_g': x_g\n",
    "        }\n",
    "\n",
    "    # get leave-one-out sums\n",
    "    y_ggi = np.ascontiguousarray(np.repeat(x_gi[None, ...], n_groups, axis=0))\n",
    "    y_ggi[np.arange(n_groups), np.arange(n_groups), :] = 0.\n",
    "    y_gi = np.sum(y_ggi, axis=1)\n",
    "\n",
    "    def rimport(packname):\n",
    "        as_environment = ri.baseenv['as.environment']\n",
    "        require = ri.baseenv['require']\n",
    "        require(ri.StrSexpVector([packname]),\n",
    "                quiet = ri.BoolSexpVector((True, )))\n",
    "        packname = ri.StrSexpVector(['package:' + str(packname)])\n",
    "        pack_env = as_environment(packname)\n",
    "        return pack_env\n",
    "    \n",
    "    rstats = rimport('stats')\n",
    "\n",
    "    pval_g = np.zeros((n_groups,))\n",
    "    \n",
    "    for i_group in range(n_groups):\n",
    "        \n",
    "        x_i = x_gi[i_group, :]\n",
    "        y_i = y_gi[i_group, :]\n",
    "        z_2i = np.vstack((x_i, y_i))\n",
    "        z_i = np.sum(z_2i, 0)\n",
    "        \n",
    "        if np.sum(x_i) == 0 or np.sum(y_i) == 0 or np.sum(z_i > 0) < 2:\n",
    "            pval = 1.\n",
    "        \n",
    "        else:            \n",
    "            contingency_table = np.hstack((x_i, y_i))\n",
    "            args = (('x', robjects.r.matrix(robjects.IntVector(contingency_table.flat), nrow=2, byrow=True)),\n",
    "                    ('simulate.p.value', True),\n",
    "                    ('B', n_mc_samples))\n",
    "            try:\n",
    "                out = rstats['fisher.test'].rcall(args, ri.globalenv)\n",
    "                pval = float(np.array(np.array(out)[0])[0])\n",
    "            except RRuntimeError:\n",
    "                print(contingency_table)\n",
    "                raise RuntimeError\n",
    "        \n",
    "        pval_g[i_group] = pval\n",
    "\n",
    "    return {\n",
    "        'pval_g': pval_g,\n",
    "        'x_g': x_g\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_id_to_p_values_map = dict()\n",
    "gene_id_to_x_g_map = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "remaining_gene_ids = list(set(gene_ids).difference(gene_id_to_p_values_map.keys()))\n",
    "num_processes = cpu_count()\n",
    "\n",
    "def process_gene_id(gene_id: str) -> Dict[str, Any]:\n",
    "\n",
    "    out = get_group_resolved_ds_pval_fisher(\n",
    "        gene_id=gene_id,\n",
    "        gene_id_to_tx_indices_map=gene_id_to_tx_indices_map,\n",
    "        group_expr_gi=group_expr_gi,\n",
    "        n_mc_samples=n_mc_samples)\n",
    "    \n",
    "    return {\n",
    "        'gene_id': gene_id,\n",
    "        'pval_g': out['pval_g'],\n",
    "        'x_g': out['x_g']\n",
    "    }\n",
    "\n",
    "with Pool(processes=num_processes) as pool:\n",
    "    for result in tqdm(pool.imap(func=process_gene_id, iterable=remaining_gene_ids), total=len(remaining_gene_ids)):\n",
    "        gene_id_to_p_values_map[result['gene_id']] = result['pval_g']\n",
    "        gene_id_to_x_g_map[result['gene_id']] = result['x_g']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate dataframe\n",
    "pvalues_dict = dict()\n",
    "for i_group, group_id in enumerate(group_ids):\n",
    "    ds_pval_group = list(map(lambda gene_id: gene_id_to_p_values_map[gene_id][i_group], gene_ids))\n",
    "    _, ds_pval_group_adj, _, _ = multipletests(ds_pval_group, alpha=0.05, method='fdr_bh')\n",
    "    pvalues_dict[f'ds_pval_{i_group}'] = ds_pval_group\n",
    "    pvalues_dict[f'ds_pval_adj_{i_group}'] = ds_pval_group_adj\n",
    "\n",
    "group_total_counts_dict = dict()\n",
    "for i_group, group_id in enumerate(group_ids):\n",
    "    group_total_counts_dict[f'expr_{i_group}'] = list(map(lambda gene_id: gene_id_to_x_g_map[gene_id][i_group], gene_ids))\n",
    "group_total_counts_dict['total_expr'] = list(map(lambda gene_id: np.sum(gene_id_to_x_g_map[gene_id]), gene_ids))\n",
    "\n",
    "group_resolved_ds_df = pd.DataFrame({\n",
    "    **dict(gene_ids=gene_ids),\n",
    "    **pvalues_dict,\n",
    "    **group_total_counts_dict},\n",
    "    index=list(map(gene_id_to_gene_name_map.get, gene_ids)),)\n",
    "\n",
    "if save_results:\n",
    "    group_resolved_ds_df.to_csv(group_resolved_ds_df_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_resolved_ds_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group-resolved differential expression analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "# get gene expression from isoform expression\n",
    "row_indices = []\n",
    "col_indices = []\n",
    "values = []\n",
    "for j, gene_id in enumerate(gene_ids):\n",
    "    tx_indices = gene_id_to_tx_indices_map[gene_id]\n",
    "    row_indices += tx_indices\n",
    "    col_indices += [j] * len(tx_indices)\n",
    "    values += [1] * len(tx_indices)\n",
    "Y_ij = scipy.sparse.coo_matrix((values, (row_indices, col_indices)), shape=(n_transcripts, n_genes)).tocsr()\n",
    "gex_X_nj = adata_long.X @ Y_ij\n",
    "\n",
    "# normalize\n",
    "adata_long_gex = sc.AnnData(\n",
    "    X=gex_X_nj,\n",
    "    obs=adata_long.obs,\n",
    "    var=pd.DataFrame(index=pd.Index(list(map(gene_id_to_gene_name_map.get, gene_ids)))))\n",
    "\n",
    "adata_long_gex.var_names_make_unique()\n",
    "sc.pp.normalize_per_cell(adata_long_gex)\n",
    "sc.pp.log1p(adata_long_gex)\n",
    "\n",
    "adata_short_sct = adata_long_gex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_resolved_ds_df = pd.read_csv(group_resolved_ds_df_csv_path, index_col=0)\n",
    "\n",
    "sc.tl.rank_genes_groups(adata_short_sct, 'mehrtash_leiden', method='t-test', use_raw=False)\n",
    "\n",
    "result = adata_short_sct.uns['rank_genes_groups']\n",
    "n_groups = len(group_ids)\n",
    "group_id_to_group_idx_map = {group_id: group_idx for group_idx, group_id in enumerate(group_ids)}\n",
    "key_to_col_name_map = {'names': 'gene_names', 'pvals': 'de_pval', 'pvals_adj': 'de_pval_adj_scanpy'}\n",
    "de_df = pd.DataFrame(\n",
    "    {key_to_col_name_map[key] + '_' + str(group_id_to_group_idx_map[group_id]): result[key][group_id]\n",
    "     for group_id in group_ids\n",
    "     for key in ['names', 'pvals', 'pvals_adj']})\n",
    "\n",
    "de_gene_names_list = adata_short_sct.var.index.values\n",
    "de_pval_list = np.zeros((len(de_gene_names_list),))\n",
    "de_gene_name_to_index_map = {gene_name: idx for idx, gene_name in enumerate(de_gene_names_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "ds_gene_names_list = group_resolved_ds_df.index.values.tolist()\n",
    "mutual_gene_names_list = list(set(ds_gene_names_list).intersection(de_gene_names_list))\n",
    "group_resolved_ds_df = group_resolved_ds_df.loc[mutual_gene_names_list]\n",
    "\n",
    "gene_name_counter = Counter(group_resolved_ds_df.index.values)\n",
    "bad_gene_names = set()\n",
    "for gene_name, multiplicity in gene_name_counter.items():\n",
    "    if multiplicity > 1:\n",
    "        bad_gene_names.add(gene_name)\n",
    "\n",
    "mutual_gene_names_list = list(set(mutual_gene_names_list).difference(bad_gene_names))\n",
    "group_resolved_ds_df = group_resolved_ds_df.loc[mutual_gene_names_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_resolved_ds_de_df = group_resolved_ds_df.copy()\n",
    "\n",
    "for group_idx, group_id in enumerate(group_ids):\n",
    "    de_group_gene_names = de_df[f'gene_names_{group_idx}'].values\n",
    "    de_group_pvals = de_df[f'de_pval_{group_idx}'].values\n",
    "    _, de_group_pvals_adj, _, _ = multipletests(de_group_pvals, alpha=0.05, method='fdr_bh')\n",
    "    de_group_gene_name_to_index_map = {gene_name: index for index, gene_name in enumerate(de_group_gene_names)}\n",
    "    group_resolved_ds_de_df[f'de_pval_{group_idx}'] = de_group_pvals[\n",
    "        list(map(de_group_gene_name_to_index_map.get, mutual_gene_names_list))]\n",
    "    group_resolved_ds_de_df[f'de_pval_adj_{group_idx}'] = de_group_pvals_adj[\n",
    "        list(map(de_group_gene_name_to_index_map.get, mutual_gene_names_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_results:\n",
    "    group_resolved_ds_de_df.to_csv(group_resolved_ds_de_df_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_resolved_ds_de_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "\n",
    "ncols = 4\n",
    "nrows = int(np.ceil(len(group_ids) / ncols))\n",
    "scale = 3.\n",
    "\n",
    "fig, axs = plt.subplots(ncols=ncols, nrows=nrows, figsize=(scale * ncols, scale * nrows))\n",
    "\n",
    "highlight_map = {\n",
    "    # ('RPL', 'red'): [gene_name for gene_name in gene_names if gene_name.find('RPL') == 0],\n",
    "    ('PTPRC', 'blue'): ['PTPRC'],\n",
    "}\n",
    "\n",
    "x_jitter_scale = 0.01\n",
    "y_jitter_scale = 0.01\n",
    "max_ds_log_pval = 3.\n",
    "max_de_log_pval = 3.\n",
    "log10_fdr_threshold = - np.log10(0.05)\n",
    "rng_seed = 0\n",
    "\n",
    "rng = np.random.RandomState(seed=rng_seed)\n",
    "gene_names_list = group_resolved_ds_de_df.index.values.tolist()\n",
    "log10_tpm = np.log10(\n",
    "    1_000_000 * group_resolved_ds_de_df['total_expr'].values /\n",
    "    np.sum(group_resolved_ds_de_df['total_expr'].values))\n",
    "\n",
    "for group_idx, ax in zip(range(len(group_ids)), axs.flatten()):\n",
    "\n",
    "    X_COL_NAME = f'de_pval_adj_{group_idx}'\n",
    "    Y_COL_NAME = f'ds_pval_adj_{group_idx}'\n",
    "\n",
    "    xx = np.minimum(-np.log10(group_resolved_ds_de_df[X_COL_NAME].values), max_de_log_pval)\n",
    "    yy = np.minimum(-np.log10(group_resolved_ds_de_df[Y_COL_NAME].values), max_ds_log_pval)\n",
    "\n",
    "    n_ds = np.sum((yy > log10_fdr_threshold) & (xx <= log10_fdr_threshold))\n",
    "    n_de = np.sum((xx > log10_fdr_threshold) & (yy <= log10_fdr_threshold))\n",
    "    n_de_ds = np.sum((xx > log10_fdr_threshold) & (yy > log10_fdr_threshold))\n",
    "    n_boring = np.sum((xx <= log10_fdr_threshold) & (yy <= log10_fdr_threshold))\n",
    "    \n",
    "    xx = np.maximum(0, xx + x_jitter_scale * np.max(xx) * rng.randn(len(xx)))\n",
    "    yy = np.maximum(0, yy + y_jitter_scale * np.max(yy) * rng.randn(len(yy)))\n",
    "\n",
    "    scatter = ax.scatter(\n",
    "        xx,\n",
    "        yy,\n",
    "        color='gray',\n",
    "        # c=log10_tpm,\n",
    "        cmap=plt.cm.Reds,\n",
    "        s=2, alpha=0.5)\n",
    "\n",
    "    ax.axhline(log10_fdr_threshold, lw=1, linestyle='--')\n",
    "    ax.axvline(log10_fdr_threshold, lw=1, linestyle='--')\n",
    "\n",
    "    for manifest, highlighted_gene_names in highlight_map.items():\n",
    "        label = manifest[0]\n",
    "        color = manifest[1]\n",
    "        indices = [\n",
    "            gene_names_list.index(gene_name)\n",
    "            for gene_name in highlighted_gene_names]\n",
    "        ax.scatter(\n",
    "            xx[indices],\n",
    "            yy[indices],\n",
    "            s=20,\n",
    "            color=color,\n",
    "            label=label,\n",
    "            marker='o',\n",
    "            facecolor=[1, 1, 1, 0],\n",
    "            linewidths=1)\n",
    "\n",
    "    ax.set_xlabel(r'$-log_{10}~P_{DE}$')\n",
    "    ax.set_ylabel(r'$-log_{10}~P_{DS}$')\n",
    "    \n",
    "    ax.text(\n",
    "        0.5 * log10_fdr_threshold, 0.5 * (np.max(yy) + log10_fdr_threshold),\n",
    "        str(n_ds),\n",
    "        fontsize=8,\n",
    "        rotation='horizontal',\n",
    "        ha='center',\n",
    "        color='red',\n",
    "        bbox=dict(boxstyle='round', facecolor='white', alpha=0.5))\n",
    "\n",
    "    ax.text(\n",
    "        0.5 * log10_fdr_threshold, 0.5 * log10_fdr_threshold,\n",
    "        str(n_boring),\n",
    "        fontsize=8,\n",
    "        rotation='horizontal',\n",
    "        ha='center',\n",
    "        color='red',\n",
    "        bbox=dict(boxstyle='round', facecolor='white', alpha=0.5))\n",
    "\n",
    "    ax.text(\n",
    "        0.5 * (np.max(xx) + log10_fdr_threshold), 0.5 * log10_fdr_threshold,\n",
    "        str(n_de),\n",
    "        fontsize=8,\n",
    "        rotation='horizontal',\n",
    "        ha='center',\n",
    "        color='red',\n",
    "        bbox=dict(boxstyle='round', facecolor='white', alpha=0.5))\n",
    "\n",
    "    ax.text(\n",
    "        0.5 * (np.max(xx) + log10_fdr_threshold), 0.5 * (np.max(yy) + log10_fdr_threshold),\n",
    "        str(n_de_ds),\n",
    "        fontsize=8,\n",
    "        rotation='horizontal',\n",
    "        ha='center',\n",
    "        color='red',\n",
    "        bbox=dict(boxstyle='round', facecolor='white', alpha=0.5))\n",
    "\n",
    "    ax.set_title(group_ids[group_idx] + \" vs. rest\")\n",
    "\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.savefig('./output/M132TS__DE_DS__t_test__adata_short_sct.png', dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-7.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-7:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
